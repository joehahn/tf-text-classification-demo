{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dl.ipynb\n",
    "#\n",
    "#by Joe Hahn\n",
    "#jmh.datasciences@gmail.com\n",
    "#24 January 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height has been deprecated.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import matplotlib pandas etc\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import rcParams\n",
    "sns.set(font_scale=1.5, font='DejaVu Sans')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.height', None)\n",
    "pd.set_option('display.width', None)\n",
    "import time\n",
    "time_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of records =  126114\n",
      "number of books =  89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>author_id</th>\n",
       "      <th>title</th>\n",
       "      <th>input_file</th>\n",
       "      <th>text_chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53137</th>\n",
       "      <td>Thomas Bulfinch</td>\n",
       "      <td>79</td>\n",
       "      <td>Bulfinch'S Mythology</td>\n",
       "      <td>iso/etext04/bllfn10.txt</td>\n",
       "      <td>shield prove thee the same who spread such sla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15081</th>\n",
       "      <td>Herman Melville</td>\n",
       "      <td>38</td>\n",
       "      <td>Moby Dick</td>\n",
       "      <td>iso/etext01/moby11.txt</td>\n",
       "      <td>No dignity in whaling? The dignity of our call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122479</th>\n",
       "      <td>Carl Von Clausewitz</td>\n",
       "      <td>11</td>\n",
       "      <td>On War</td>\n",
       "      <td>iso/etext99/1onwr10.txt</td>\n",
       "      <td>to that amphibious organisation which we call ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34719</th>\n",
       "      <td>Immanuel Kant</td>\n",
       "      <td>42</td>\n",
       "      <td>The Critique Of Pure Reason</td>\n",
       "      <td>iso/etext03/cprrn10.txt</td>\n",
       "      <td>which I have named figurative synthesis. This ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103631</th>\n",
       "      <td>Miquel De Cervantes</td>\n",
       "      <td>62</td>\n",
       "      <td>Don Quixote</td>\n",
       "      <td>iso/etext97/1donq10.txt</td>\n",
       "      <td>of our vigils, lust and lewdness by the loyalt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     author  author_id                        title  \\\n",
       "53137       Thomas Bulfinch         79         Bulfinch'S Mythology   \n",
       "15081       Herman Melville         38                    Moby Dick   \n",
       "122479  Carl Von Clausewitz         11                       On War   \n",
       "34719         Immanuel Kant         42  The Critique Of Pure Reason   \n",
       "103631  Miquel De Cervantes         62                  Don Quixote   \n",
       "\n",
       "                     input_file  \\\n",
       "53137   iso/etext04/bllfn10.txt   \n",
       "15081    iso/etext01/moby11.txt   \n",
       "122479  iso/etext99/1onwr10.txt   \n",
       "34719   iso/etext03/cprrn10.txt   \n",
       "103631  iso/etext97/1donq10.txt   \n",
       "\n",
       "                                               text_chunk  \n",
       "53137   shield prove thee the same who spread such sla...  \n",
       "15081   No dignity in whaling? The dignity of our call...  \n",
       "122479  to that amphibious organisation which we call ...  \n",
       "34719   which I have named figurative synthesis. This ...  \n",
       "103631  of our vigils, lust and lewdness by the loyalt...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read 'chunks' dataframe; each record contains a random 100-word-long chunk of text from one of 89\n",
    "#books from the gutenberg project\n",
    "import pickle\n",
    "with open('chunks.pkl', 'rb') as fp:\n",
    "    chunks = pickle.load(fp)\n",
    "print 'number of records = ', len(chunks)\n",
    "print 'number of books = ', len(chunks['input_file'].unique())\n",
    "chunks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>input_file</th>\n",
       "      <th>N_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A.H. Clough</td>\n",
       "      <td>Plutarch's Lives</td>\n",
       "      <td>iso/etext96/plivs10.txt</td>\n",
       "      <td>2200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adam Smith</td>\n",
       "      <td>Wealth Of Nations</td>\n",
       "      <td>iso/etext02/wltnt10.txt</td>\n",
       "      <td>2200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adams</td>\n",
       "      <td>The Education Of Henry Adams</td>\n",
       "      <td>iso/etext00/eduha10.txt</td>\n",
       "      <td>1260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anne C. Lynch Botta</td>\n",
       "      <td>Handbook Of Universal Literature</td>\n",
       "      <td>iso/etext05/8unlt10.txt</td>\n",
       "      <td>1699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anthony Trollope</td>\n",
       "      <td>The Last Chronicle Of Barset</td>\n",
       "      <td>iso/etext02/lacob11.txt</td>\n",
       "      <td>2200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                author                             title  \\\n",
       "0          A.H. Clough                  Plutarch's Lives   \n",
       "1           Adam Smith                 Wealth Of Nations   \n",
       "2                Adams      The Education Of Henry Adams   \n",
       "3  Anne C. Lynch Botta  Handbook Of Universal Literature   \n",
       "4     Anthony Trollope      The Last Chronicle Of Barset   \n",
       "\n",
       "                input_file  N_chunks  \n",
       "0  iso/etext96/plivs10.txt      2200  \n",
       "1  iso/etext02/wltnt10.txt      2200  \n",
       "2  iso/etext00/eduha10.txt      1260  \n",
       "3  iso/etext05/8unlt10.txt      1699  \n",
       "4  iso/etext02/lacob11.txt      2200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show titles and number of chunks\n",
    "#need to fix Austnn & Jane Austen\n",
    "N = pd.DataFrame(chunks.groupby(['author', 'title', 'input_file'])['text_chunk'].count()).reset_index()\\\n",
    "    .sort_values('author')\n",
    "N = N.rename(columns={'text_chunk':'N_chunks'})\n",
    "N.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Private Life Of Napoleon' 'The Junior Classics' 'Howards End'\n",
      " 'Cyropaedia' 'Sister Carrie' 'The Complete Poetical Works of Percy Bysshe'\n",
      " 'Ulysses' 'Rob Roy' 'The Caxtons' 'Life Of Luther'\n",
      " 'Forbidden Gospels and Epistles, Complete' 'The Iliad' 'She'\n",
      " 'Science & Education' 'The Zambesi Expedition' 'The Rosary' 'Little Women'\n",
      " 'Unbeaten Tracks In Japan' 'On War' 'History Of American Literature']\n",
      "number of records =  23164\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>author_id</th>\n",
       "      <th>title</th>\n",
       "      <th>input_file</th>\n",
       "      <th>text_chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12046</th>\n",
       "      <td>Constant</td>\n",
       "      <td>11</td>\n",
       "      <td>Private Life Of Napoleon</td>\n",
       "      <td>iso/etext02/nc13v11.txt</td>\n",
       "      <td>marshal of France, the defense of one of the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12852</th>\n",
       "      <td>Constant</td>\n",
       "      <td>11</td>\n",
       "      <td>Private Life Of Napoleon</td>\n",
       "      <td>iso/etext02/nc13v11.txt</td>\n",
       "      <td>indirectly sounded, or even openly solicited, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21872</th>\n",
       "      <td>Various</td>\n",
       "      <td>18</td>\n",
       "      <td>The Junior Classics</td>\n",
       "      <td>iso/etext04/8jrc710.txt</td>\n",
       "      <td>as he could not write, was taken down at his d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11045</th>\n",
       "      <td>Constant</td>\n",
       "      <td>11</td>\n",
       "      <td>Private Life Of Napoleon</td>\n",
       "      <td>iso/etext02/nc13v11.txt</td>\n",
       "      <td>age. In his youth he had lived in France, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13244</th>\n",
       "      <td>E. M. Forster</td>\n",
       "      <td>12</td>\n",
       "      <td>Howards End</td>\n",
       "      <td>iso/etext01/hoend10.txt</td>\n",
       "      <td>admit that, if wealth was divided up equally, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22668</th>\n",
       "      <td>Xenophon</td>\n",
       "      <td>19</td>\n",
       "      <td>Cyropaedia</td>\n",
       "      <td>iso/etext00/cyrus10.txt</td>\n",
       "      <td>meet the foe?\" [2] Hystaspas took up the chall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11397</th>\n",
       "      <td>Constant</td>\n",
       "      <td>11</td>\n",
       "      <td>Private Life Of Napoleon</td>\n",
       "      <td>iso/etext02/nc13v11.txt</td>\n",
       "      <td>an enjoyment, from which no other pleasure, ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>Theodore Dreiser</td>\n",
       "      <td>1</td>\n",
       "      <td>Sister Carrie</td>\n",
       "      <td>iso/etext95/scarr10.txt</td>\n",
       "      <td>rush of fright, however, the players got over ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18339</th>\n",
       "      <td>Percy Bysshe Shelley</td>\n",
       "      <td>16</td>\n",
       "      <td>The Complete Poetical Works of Percy Bysshe</td>\n",
       "      <td>iso/etext03/shlyc10.txt</td>\n",
       "      <td>Of their oracular statues; from two shrines Tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14645</th>\n",
       "      <td>James Joyce</td>\n",
       "      <td>14</td>\n",
       "      <td>Ulysses</td>\n",
       "      <td>iso/etext03/ulyss12.txt</td>\n",
       "      <td>of the EXPRESS. Scavenging what the quality le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20007</th>\n",
       "      <td>Sir Walter Scott,</td>\n",
       "      <td>17</td>\n",
       "      <td>Rob Roy</td>\n",
       "      <td>iso/etext04/rob3w10.txt</td>\n",
       "      <td>Mr. Osbaldistone to Luckie Flyter's, at the co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12435</th>\n",
       "      <td>Constant</td>\n",
       "      <td>11</td>\n",
       "      <td>Private Life Of Napoleon</td>\n",
       "      <td>iso/etext02/nc13v11.txt</td>\n",
       "      <td>an apartment used for grand diplomatic recepti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12625</th>\n",
       "      <td>Constant</td>\n",
       "      <td>11</td>\n",
       "      <td>Private Life Of Napoleon</td>\n",
       "      <td>iso/etext02/nc13v11.txt</td>\n",
       "      <td>placed it on his head himself. It was a golden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4098</th>\n",
       "      <td>Bulwer-Lytton,</td>\n",
       "      <td>4</td>\n",
       "      <td>The Caxtons</td>\n",
       "      <td>iso/etext05/b033w10.txt</td>\n",
       "      <td>the grating wheels thundering low; near and ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8344</th>\n",
       "      <td>Julius Koestlin</td>\n",
       "      <td>8</td>\n",
       "      <td>Life Of Luther</td>\n",
       "      <td>iso/etext05/8luth10.txt</td>\n",
       "      <td>on that point the Evangelicals needed no admon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10680</th>\n",
       "      <td>Archbishop Wake</td>\n",
       "      <td>10</td>\n",
       "      <td>Forbidden Gospels and Epistles, Complete</td>\n",
       "      <td>iso/etext04/fb10w11.txt</td>\n",
       "      <td>to them privately, Do not act thus; I have fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4683</th>\n",
       "      <td>Bulwer-Lytton,</td>\n",
       "      <td>4</td>\n",
       "      <td>The Caxtons</td>\n",
       "      <td>iso/etext05/b033w10.txt</td>\n",
       "      <td>no answer. \"Lord Castleton has arranged all, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21207</th>\n",
       "      <td>Sir Walter Scott,</td>\n",
       "      <td>17</td>\n",
       "      <td>Rob Roy</td>\n",
       "      <td>iso/etext04/rob3w10.txt</td>\n",
       "      <td>who had sate at the feet o' his father Solomon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10992</th>\n",
       "      <td>Constant</td>\n",
       "      <td>11</td>\n",
       "      <td>Private Life Of Napoleon</td>\n",
       "      <td>iso/etext02/nc13v11.txt</td>\n",
       "      <td>prosperity; adversity will find me above the r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10900</th>\n",
       "      <td>Archbishop Wake</td>\n",
       "      <td>10</td>\n",
       "      <td>Forbidden Gospels and Epistles, Complete</td>\n",
       "      <td>iso/etext04/fb10w11.txt</td>\n",
       "      <td>God are a broken spirit; a broken and a contri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     author  author_id  \\\n",
       "12046              Constant         11   \n",
       "12852              Constant         11   \n",
       "21872               Various         18   \n",
       "11045              Constant         11   \n",
       "13244         E. M. Forster         12   \n",
       "22668              Xenophon         19   \n",
       "11397              Constant         11   \n",
       "956        Theodore Dreiser          1   \n",
       "18339  Percy Bysshe Shelley         16   \n",
       "14645           James Joyce         14   \n",
       "20007     Sir Walter Scott,         17   \n",
       "12435              Constant         11   \n",
       "12625              Constant         11   \n",
       "4098         Bulwer-Lytton,          4   \n",
       "8344        Julius Koestlin          8   \n",
       "10680       Archbishop Wake         10   \n",
       "4683         Bulwer-Lytton,          4   \n",
       "21207     Sir Walter Scott,         17   \n",
       "10992              Constant         11   \n",
       "10900       Archbishop Wake         10   \n",
       "\n",
       "                                             title               input_file  \\\n",
       "12046                     Private Life Of Napoleon  iso/etext02/nc13v11.txt   \n",
       "12852                     Private Life Of Napoleon  iso/etext02/nc13v11.txt   \n",
       "21872                          The Junior Classics  iso/etext04/8jrc710.txt   \n",
       "11045                     Private Life Of Napoleon  iso/etext02/nc13v11.txt   \n",
       "13244                                  Howards End  iso/etext01/hoend10.txt   \n",
       "22668                                   Cyropaedia  iso/etext00/cyrus10.txt   \n",
       "11397                     Private Life Of Napoleon  iso/etext02/nc13v11.txt   \n",
       "956                                  Sister Carrie  iso/etext95/scarr10.txt   \n",
       "18339  The Complete Poetical Works of Percy Bysshe  iso/etext03/shlyc10.txt   \n",
       "14645                                      Ulysses  iso/etext03/ulyss12.txt   \n",
       "20007                                      Rob Roy  iso/etext04/rob3w10.txt   \n",
       "12435                     Private Life Of Napoleon  iso/etext02/nc13v11.txt   \n",
       "12625                     Private Life Of Napoleon  iso/etext02/nc13v11.txt   \n",
       "4098                                   The Caxtons  iso/etext05/b033w10.txt   \n",
       "8344                                Life Of Luther  iso/etext05/8luth10.txt   \n",
       "10680     Forbidden Gospels and Epistles, Complete  iso/etext04/fb10w11.txt   \n",
       "4683                                   The Caxtons  iso/etext05/b033w10.txt   \n",
       "21207                                      Rob Roy  iso/etext04/rob3w10.txt   \n",
       "10992                     Private Life Of Napoleon  iso/etext02/nc13v11.txt   \n",
       "10900     Forbidden Gospels and Epistles, Complete  iso/etext04/fb10w11.txt   \n",
       "\n",
       "                                              text_chunk  \n",
       "12046  marshal of France, the defense of one of the f...  \n",
       "12852  indirectly sounded, or even openly solicited, ...  \n",
       "21872  as he could not write, was taken down at his d...  \n",
       "11045  age. In his youth he had lived in France, and ...  \n",
       "13244  admit that, if wealth was divided up equally, ...  \n",
       "22668  meet the foe?\" [2] Hystaspas took up the chall...  \n",
       "11397  an enjoyment, from which no other pleasure, ho...  \n",
       "956    rush of fright, however, the players got over ...  \n",
       "18339  Of their oracular statues; from two shrines Tw...  \n",
       "14645  of the EXPRESS. Scavenging what the quality le...  \n",
       "20007  Mr. Osbaldistone to Luckie Flyter's, at the co...  \n",
       "12435  an apartment used for grand diplomatic recepti...  \n",
       "12625  placed it on his head himself. It was a golden...  \n",
       "4098   the grating wheels thundering low; near and ne...  \n",
       "8344   on that point the Evangelicals needed no admon...  \n",
       "10680  to them privately, Do not act thus; I have fou...  \n",
       "4683   no answer. \"Lord Castleton has arranged all, s...  \n",
       "21207  who had sate at the feet o' his father Solomon...  \n",
       "10992  prosperity; adversity will find me above the r...  \n",
       "10900  God are a broken spirit; a broken and a contri...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select 10 books\n",
    "records = pd.DataFrame()\n",
    "old_ids = [11, 78, 81, 8, 10, 20, 30, 40, 50, 70]\n",
    "old_ids = [11, 78, 81, 8, 10, 20, 30, 40, 50, 70, 5, 15, 25, 35, 45, 55, 65, 75, 85, 88]\n",
    "for new_id in range(len(old_ids)):\n",
    "    idx = chunks['author_id'] == old_ids[new_id]\n",
    "    df = chunks[idx].copy()\n",
    "    df['author_id'] = new_id\n",
    "    records = records.append(df, ignore_index=True)\n",
    "records = records.sample(frac=1.0)\n",
    "print records['title'].unique()\n",
    "print 'number of records = ', len(records)\n",
    "records.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records.shape  =  (23164, 5)\n",
      "train.shape    =  (7644, 5)\n",
      "test.shape     =  (7760, 5)\n",
      "validate.shape =  (7760, 5)\n"
     ]
    }
   ],
   "source": [
    "#train-test-validate split\n",
    "train_size = 0.33\n",
    "validate_size=0.5   #this is the fraction of the test sample that is assigned to the validation sample\n",
    "rn_seed = 12\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(records, train_size=train_size, random_state=rn_seed)\n",
    "validate, test = train_test_split(test, train_size=validate_size, random_state=rn_seed)\n",
    "print 'records.shape  = ', records.shape\n",
    "print 'train.shape    = ', train.shape\n",
    "print 'test.shape     = ', test.shape\n",
    "print 'validate.shape = ', validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20\n"
     ]
    }
   ],
   "source": [
    "#confirm that all 90 books have records in the training sample\n",
    "print len(train['input_file'].unique()), len(records['input_file'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of distinct words =  81867\n",
      "fawn 1\n",
      "lenitives 1\n",
      "considered. 2\n",
      "creeps, 1\n",
      "vertebr�, 1\n",
      "Moeris 1\n"
     ]
    }
   ],
   "source": [
    "#count number of distinct workds in training data...43K\n",
    "from collections import defaultdict\n",
    "word_frequency = defaultdict(int)\n",
    "corpus = train['text_chunk'].tolist()\n",
    "for doc in corpus:\n",
    "    words = doc.split(' ')\n",
    "    for word in words:\n",
    "        word_frequency[word] += 1\n",
    "print 'number of distinct words = ', len(word_frequency.keys()) \n",
    "for word in word_frequency.keys()[1:7]:\n",
    "    print word, word_frequency[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate tokenizer\n",
    "vocabulary_size = 82000#43000\n",
    "N_inputs = 100\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "tokenizer = Tokenizer(num_words=vocabulary_size)\n",
    "tokenizer.fit_on_texts(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this helper function extracts and tokenizes x, and extracts y and onehot-encodes it\n",
    "from keras.utils import np_utils\n",
    "def tokenize(df, tokenizer):\n",
    "    corpus = df['text_chunk'].tolist()\n",
    "    corpus_tokenized = tokenizer.texts_to_sequences(corpus)\n",
    "    corpus_padded = pad_sequences(corpus_tokenized, maxlen=N_inputs)\n",
    "    x = np.array(corpus_padded)\n",
    "    y_ids = df['author_id'].values\n",
    "    y = np_utils.to_categorical(y_ids)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape =  (7644, 100)\n",
      "y_train.shape =  (7644, 20)\n",
      "N_inputs =  100\n",
      "N_outputs =  20\n",
      "vocabulary_size =  82000 0 36735\n"
     ]
    }
   ],
   "source": [
    "#get training x,y with x-values being tokenized and y values onehot-encoded\n",
    "x_train, y_train = tokenize(train, tokenizer)\n",
    "N_inputs = x_train.shape[1]\n",
    "N_outputs = y_train.shape[1]\n",
    "print 'x_train.shape = ', x_train.shape\n",
    "print 'y_train.shape = ', y_train.shape\n",
    "print 'N_inputs = ', N_inputs\n",
    "print 'N_outputs = ', N_outputs\n",
    "print 'vocabulary_size = ', vocabulary_size, x_train.min(), x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author                                                    Homer\n",
      "author_id                                                     7\n",
      "title                                                 The Iliad\n",
      "input_file                             iso/etext04/iliad10a.txt\n",
      "text_chunk    thy now forfeit life? Or that again our camps ...\n",
      "Name: 7626, dtype: object\n",
      "thy now forfeit life? Or that again our camps thou may'st explore? No--once a traitor, thou betray'st no more.\" Sternly he spoke, and as the wretch prepared With humble blandishment to stroke his beard, Like lightning swift the wrathful falchion flew, Divides the neck, and cuts the nerves in two; One instant snatch'd his trembling soul to hell, The head, yet speaking, mutter'd as it fell. The furry helmet from his brow they tear, The wolf's grey hide, the unbended bow and spear; These great Ulysses lifting to the skies, To favouring Pallas dedicates the prize: \"Great queen of arms, \n",
      "[   57  9841   109    41     7   130    61  5048   115 18172  7739    46\n",
      "   164     5  8537   115 31327    46    53  7532     8   375     2    14\n",
      "     1  3459   957    12  2556 34105     4  3177    10  4178    60  2166\n",
      "   774     1 15084  9169  1413  9164     1  1408     2  9935     1  2456\n",
      "     6    89    39  1513  9068    10  1180   287     4  1132     1   178\n",
      "   118   914 21899    14    13   326     1 20626  2968    27    10  1568\n",
      "    33  2368     1 16638  1155  1901     1 33314  1391     2  1311    70\n",
      "    77  1858  4396     4     1  1229     4 11152  4203 26107     1  1660\n",
      "    77   621     3   216]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "#display a training record\n",
    "idx = 121\n",
    "print train.iloc[idx]\n",
    "text_chunk = train.iloc[idx]['text_chunk']\n",
    "print text_chunk\n",
    "print x_train[idx]\n",
    "print y_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thy', 'now', 'forfeit', 'life', 'or', 'that', 'again', 'our']\n",
      "[119, 57, 9841, 109, 41, 7, 130, 61]\n"
     ]
    }
   ],
   "source": [
    "#show that the vectorized text preserves word order with punctuation dropping \n",
    "tokens = []\n",
    "words_marked = text_chunk.split(' ')[0:8]\n",
    "words = [word.lower().strip(',').strip('.').strip('\"').strip('?') for word in words_marked]\n",
    "tokens = [tokenizer.word_index[word] for word in words]\n",
    "print words\n",
    "print tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_valid.shape =  (7760, 100)\n",
      "y_valid.shape =  (7760, 20)\n"
     ]
    }
   ],
   "source": [
    "#get validation x,y with x-values being tokenized and y values onehot-encoded\n",
    "x_valid, y_valid = tokenize(validate, tokenizer)\n",
    "print 'x_valid.shape = ', x_valid.shape\n",
    "print 'y_valid.shape = ', y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author                                                     Bird\n",
      "author_id                                                     3\n",
      "title                                  Unbeaten Tracks In Japan\n",
      "input_file                              iso/etext00/utrkj10.txt\n",
      "text_chunk    dance, in which men alone take part. Yells and...\n",
      "Name: 2751, dtype: object\n",
      "dance, in which men alone take part. Yells and shouts are used to excite the bear, and when he becomes much agitated a chief shoots him with an arrow, inflicting a slight wound which maddens him, on which the bars of the cage are raised, and he springs forth, very furious. At this stage the Ainos run upon him with various weapons, each one striving to inflict a wound, as it brings good luck to draw his blood. As soon as he falls down exhausted, his head is cut off, and the weapons with which he has been wounded are \n",
      "[   23     1   341     3    45 13362  3267    21     9   346    87  1638\n",
      "    13     6     1  1816   105   100    36   129  1940    91    65  4557\n",
      "     9    34     5  6152   283   120    20     9   532    19  6707     4\n",
      "   132    23     4     9   537     7    13    16    19   213 31397     2\n",
      "  1587    96  1037     2   504     1 11470   530   112    56  1587     2\n",
      "     1  1940   540   102 11201  1344     2  2156    86     5   292   180\n",
      "     3  3742   877  1940 10505    48   203    12     5 20639  3852  1938\n",
      "     1   126     4     1   715   602  3937     5   197     2   302     1\n",
      "  8995     4     5   292]\n",
      "[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "#display a validation record\n",
    "idx = 123\n",
    "print validate.iloc[idx]\n",
    "print validate.iloc[idx]['text_chunk']\n",
    "print x_valid[321]\n",
    "print y_valid[321]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this LSTM model was adapted from \n",
    "#http://www.developintelligence.com/blog/2017/06/practical-neural-networks-keras-classifying-yelp-reviews\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Conv1D, MaxPooling1D\n",
    "from keras.models import Sequential\n",
    "def build_lstm_model(N_inputs, N_outputs, vocabulary_size, embedding_vector_length, conv_kernel_size, dropout_fraction):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocabulary_size, embedding_vector_length, input_length=N_inputs))\n",
    "    conv_layer_size = embedding_vector_length/2\n",
    "    model.add(Conv1D(conv_layer_size, conv_kernel_size, activation='relu'))\n",
    "    model.add(Dropout(dropout_fraction))\n",
    "    pool_size = int(conv_kernel_size/2)\n",
    "    model.add(MaxPooling1D(pool_size=pool_size))\n",
    "    lstm_size = int(embedding_vector_length/2)\n",
    "    model.add(LSTM(lstm_size, activation='tanh')) #try linear, tanh, relu\n",
    "    model.add(Dropout(dropout_fraction))\n",
    "    model.add(Dense(N_outputs, activation='sigmoid'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_training_epochs =  50\n",
      "batch_size =  1000\n",
      "number of training + validation samples =  15404\n",
      "vocabulary_size =  82000\n",
      "embedding_vector_length =  300\n",
      "conv_kernel_size =  50\n",
      "dropout_fraction =  0.3\n",
      "N_inputs =  100 100\n",
      "N_outputs =  20 20\n",
      "rn_seed =  16\n"
     ]
    }
   ],
   "source": [
    "#assemble lstm model\n",
    "N_training_epochs = 50\n",
    "batch_size = 1000\n",
    "embedding_vector_length = 300\n",
    "conv_kernel_size = 50\n",
    "dropout_fraction = 0.3\n",
    "rn_seed = 16\n",
    "print 'N_training_epochs = ', N_training_epochs\n",
    "print 'batch_size = ', batch_size\n",
    "print 'number of training + validation samples = ', x_train.shape[0] + x_valid.shape[0]\n",
    "print 'vocabulary_size = ', vocabulary_size\n",
    "print 'embedding_vector_length = ', embedding_vector_length\n",
    "print 'conv_kernel_size = ', conv_kernel_size\n",
    "print 'dropout_fraction = ', dropout_fraction\n",
    "print 'N_inputs = ', N_inputs, x_train.shape[1]\n",
    "print 'N_outputs = ', N_outputs, y_train.shape[1]\n",
    "print 'rn_seed = ', rn_seed\n",
    "import random\n",
    "random.seed(rn_seed)\n",
    "lstm_model = build_lstm_model(N_inputs, N_outputs, vocabulary_size, embedding_vector_length, conv_kernel_size,\n",
    "    dropout_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fit model to the training data...this takes X minutes on g2.2xl instance\n",
    "from time import time\n",
    "from keras.callbacks import TensorBoard\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "fit_history = lstm_model.fit(x_train, y_train, epochs=N_training_epochs, batch_size=batch_size, verbose=0, \\\n",
    "    validation_data=(x_valid, y_valid), callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot accuracy vs training epoch\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 6))\n",
    "xp = fit_history.epoch\n",
    "yp = fit_history.history['acc']\n",
    "ax.plot(xp, yp, label='training sample')\n",
    "yp = fit_history.history['val_acc']\n",
    "ax.plot(xp, yp, label='validation sample')\n",
    "ax.set_title('classifier accuracy versus epoch')\n",
    "ax.set_ylabel('accuracy')\n",
    "ax.set_xlabel('training epoch')\n",
    "ax.legend()\n",
    "plt.savefig('figs/accuracy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot loss function vs training epoch\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 6))\n",
    "xp = fit_history.epoch\n",
    "yp = fit_history.history['loss']\n",
    "ax.plot(xp, yp, label='training sample')\n",
    "yp = fit_history.history['val_loss']\n",
    "ax.plot(xp, yp, label='validation sample')\n",
    "ax.set_title('loss function versus epoch')\n",
    "ax.set_ylabel('loss function')\n",
    "ax.set_xlabel('training epoch')\n",
    "ax.legend()\n",
    "plt.savefig('figs/loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#done!\n",
    "print 'loss fn  = ', fit_history.history['loss'][-1]\n",
    "print 'accuracy = ', fit_history.history['val_acc'][-1]\n",
    "time_stop = time.time()\n",
    "print 'execution time (minutes) = ', (time_stop - time_start)/60.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
